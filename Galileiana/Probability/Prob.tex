\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{nicefrac}
\usepackage[margin=3.3cm]{geometry}
\usepackage{amssymb}
\usepackage[italian]{babel}
\usepackage{accents}
\usepackage{amsthm}
\usepackage[pdftex, pdfborderstyle={/S/U/W 0}]{hyperref}
\numberwithin{equation}{section}
\usepackage{commath}
\usepackage{graphicx}
%\usepackage[extreme]{savetrees}
\usepackage{bm}
\usepackage{indentfirst}
\usepackage{nicefrac}
\setcounter{tocdepth}{4}
\usepackage{fnpct}
\usepackage{centernot}

\usepackage{cool}
\Style{DSymb={\mathrm d},DShorten=true,IntegrateDifferentialDSymb=\mathrm{d}}

\usepackage{microtype}
\usepackage{cleveref}
\usepackage{tensor}

\theoremstyle{definition}
\newtheorem{definition}{Definizione}[section]
\usepackage{mathtools}
 
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{url}
\newcommand*{\defeq}{\stackrel{\text{def}}{=}}
\author{Jacopo Tissino}
\title{Modelli probabilistici}

\begin{document}

\maketitle

\section{Basi}

\begin{definition}
\emph{Esperimento aleatorio}: osservazione su un fenomeno il cui esito non è determinabile a priori.
\end{definition}

\begin{definition}
\emph{Spazio di probabilità}: terna di 

\begin{enumerate}
\item Spazio campionario $\Omega$: l'insieme degli esiti possibili;
\item Evento: elemento di $\mathcal{P}(\Omega)$;
\item Probabilità: $\mathbb{P}: \mathcal{P}: \Omega \rightarrow [0, 1]$ tale che:
\begin{enumerate}
\item $\mathbb{P}(\Omega) = 1$;
\item $\sigma$-additività: $\forall$ successione di eventi $(A_n)_{n \in \mathbb{N}}$:
\begin{equation}
\mathbb{P}\left(\displaystyle \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty \mathbb{P} (A_n)
\end{equation}
\end{enumerate}
\end{enumerate}
\end{definition}

Le operazioni logiche fra eventi sono equivalenti a quelle insiemistiche fra sottoinsiemi di $\Omega$. Valgono i teoremi di De Morgan, anche per insiemi numerabili.

Eventi ``disgiunti'' hanno intersezione nulla. Dalla $\sigma$-additività deriva l'additività finita.

Proprietà immediate: $\forall A, B \in \mathcal{P} (\Omega)$:

\begin{enumerate}
\item $\mathbb{P}(B \smallsetminus A) = \mathbb{P}(B) - \mathbb{P}(B \cap A)$;
\item $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B) \leq \mathbb{P}(A) + \mathbb{P}(B)$.
\end{enumerate}

\begin{definition}
La funzione $p: \Omega \rightarrow [0, 1]$ è una \emph{densità di probabilità} se:

\begin{enumerate}
\item $\forall \omega \in \Omega: p(\omega) \geq 0$;
\item $\sum_{\omega \in \Omega} p(\omega) = 1$. 
\end{enumerate}
\end{definition}

\begin{theorem}
Data la funzione $p: \Omega \rightarrow [0, 1]$, la funzione $\mathbb{P}: \mathcal{P}(\Omega) \rightarrow [0, 1]$ tale che $\forall A \subseteq \Omega: \mathbb{P}(A) = \sum_{\omega \in A} p(\omega)$ è una probabilità.

Vale anche il viceversa: data $\mathbb{P}: \mathcal{P}(\Omega) \rightarrow [0, 1]$ la funzione $p: \Omega \rightarrow [0, 1]$ tale che $p(\omega) = \mathbb{P} (\lbrace \omega \rbrace )$ è una densità di probabilità.
\end{theorem}

\paragraph{Esempi di spazi discreti}

Per uno spazio uniforme, per il quale $\abs{\Omega} \in \mathbb{N}$, $\forall \omega \in \Omega: p(\omega) = 1/\abs{\Omega}$.

\paragraph{Richiami di combinatoria}

Scegliamo $k$ elementi da $n$:

\begin{enumerate}
\item Disposizioni con ripetizione: $n^k$;
\item Disposizioni semplici: $\prod_{i=n-k+1}^n i = n! / (n-k+1)!$;
\item Combinazioni semplici: $C_{n, k} = { n \choose k } = n! / (k! (n-k)!)$.
\end{enumerate}

\subparagraph{Coefficienti multinomiali}

Vogliamo dividere $n$ elementi in $k$ gruppi, di cardinalità $(n_i)$, con $\sum_i n_i = n$. Si può fare in un numero di modi pari a:

\begin{equation}
{n \choose n_1, n_2, \dots, n_k } = \frac{n!}{\prod_{i=1}^k n_i !}
\end{equation}

\section{Modello di Ising}

Dato lo spazio finito $\Omega$ e data la funzione Hamiltoniana $H: \Omega \rightarrow \mathbb{R}$ (~energia) con parametro $\beta \geq 0$. Definiamo $\forall \omega \in \Omega$ la \emph{Misura di Gibbs}:

\begin{equation}
p_\beta = \frac{e^{-\beta H(\omega)}}{z_\beta} = \frac{e^{-\beta H(\omega)}}{\displaystyle\sum_{\omega \in \Omega} e^{-\beta H(\omega)}}
\end{equation}

è una ddp. Interpretazione fisica: $\beta^{-1} = k_B T$. La misura dà la probabilità di osservare un certo stato all'equilibrio.

Casi limite: $\beta \approx 0$ densità uniforme, $\beta \rightarrow \infty$ densità zero ovunque, uniforme nel minimo.

Un grafo è un insieme di vertici e spigoli: $G = (V, E), E \subseteq V\times V$. Definiamo quindi lo spazio:

\begin{equation}
\mathbb{Z} ^n = \left(\mathbb{Z} ^n, (x, y) \in \mathbb{Z} ^n:\text{d}(x, y) = 1 \right)
\end{equation}

Un sottografo finito $\Lambda \subset \mathbb{Z}^n$ è considerato con tutti i suoi spigoli: $E(\Lambda) = \lbrace (x, y) : x, y \in \Lambda, (x, y) \in E (\mathbb{Z}^n ) \rbrace$.

Ogni vertice assume valore $\pm 1$. Lo spazio è dunque $\Omega = \lbrace \pm 1 \rbrace ^{\abs{\Lambda}}$; $\sigma$ è uno stato, ovvero $\sigma \in \Omega \implies \sigma = (\sigma_k)_{k \in \Lambda}$.

Per comodità, $\text{d} (x, y) = 1 \iff x \sim y$.

Definiamo $\partial \Lambda = \lbrace x \in \Lambda : \exists y \in \Lambda^C : x\sim y \rbrace$.
Sia quindi $\tau = \lbrace \pm 1 \rbrace ^{\abs{\Lambda^C}}$ l'esterno del reticolo. Definiamo l'Hamiltoniana

\begin{equation}
H_\Lambda^\tau (\sigma ) = - \frac 12 \sum_{\substack{x, y \in \Lambda \\ x \sim y}} \sigma_x \sigma_y - \sum_{\substack{x \in \partial \Lambda \\ y \in \Lambda^C \\ x \sim y}} \sigma_x \tau_y
\end{equation}

Consideriamo solo reticoli ``quadrati'': $\Lambda_n = \lbrace -n, \dots, n \rbrace ^d \subset \mathbb{Z}^d$. Poniamo $\tau = +1$.

\section{Passeggiata aleatoria semplice unidimensionale}

Dato $n \in \mathbb{N}$,  $S_n \in \mathbb{Z}$ è la posizione assunta al passo $n$. Le regole sono:

\begin{enumerate}
\item $S_0 = 0$;
\item $S_n = k \implies S{n+1} \in \lbrace k+1, k-1 \rbrace$.
\end{enumerate}

$\mathbb{P} (S_{n+1} = k+1 | S_n = k) := p$. La passeggiata aleatoria, quindi, è la successione $(S_n)_{n\in \mathbb{N}}$. Se $p=1/2$, la passeggiata è simmetrica.

Possiamo trovare una biiezione fra le $(S_n)_{n \in \mathbb{N}}$ e le successioni $(X_n)_{n \in \mathbb{N}}$, con $X_i$ iid e tali che $\mathbb{P}(X_k = 1) = p$, $\mathbb{P}(X_k = -1) = 1-p$:

\begin{equation}
S_n = \sum_{i=1}^n X_i
\end{equation}

Sia $\Omega = \lbrace -1, +1 \rbrace ^\mathbb{N}$ l'insieme delle possibili successioni $( X_n )_{n\in \mathbb{N}}$. La nostra probabilità $\mathbb{P}$ tiene conto di tutte queste. Possiamo, chiaramente, calcolarla anche per un certo evento $A_n$ dipendente dalle $(X_i)_{i=1\dots n}$.

Troviamo quindi alcuni valori:

\begin{equation}
\mathbb{E}(S_n) = n (2p -1)
\end{equation}

\begin{equation}
\text{var} S_n = 4pn (1-p) = \sigma^2
\end{equation}

\subsection{Legge di $S_n$}

Vogliamo trovare $\mathbb{P}(S_n = j)$. Chiamiamo $n_+$ il numero di $k$ per cui $X_k=1$, e $n_- = n - n_+$. Quindi $\lbrace S_n = j \rbrace = \lbrace n_+ = (j+n)/2 \rbrace $.

Dunque $(j+n)/2 \notin \mathbb{N} \implies \mathbb{P}(S_n = j) = 0$.

\begin{equation}
\mathbb{P} (S_n = j) = {n \choose \frac{n+j}{2} } p^{\frac{n+j}{2}} (1-p) ^{\frac{n-j}{2}}
\end{equation}

\subsection{Transienza}

\begin{equation}
R = \lim_{n \rightarrow \infty} \mathbb{P} (\exists k \in \mathbb{N} \smallsetminus \lbrace 0 \rbrace, k \leq n : S_k = 0 )
\end{equation}

Il limite esiste ed è $\leq 1$. Dimostriamo che $p = 1/2 \iff R=1$.

$u_{2n} = \mathbb{P} (S_{2n} = 0)$ e $f_{2n} = \mathbb{P}(S_{2n} = 0, \forall k < 2n : S_k \neq 0 )$.

Dimostriamo che

\begin{equation}
R_{2n} = \sum_{k=0}^{n} f_{2k}
\end{equation}

\subsubsection{Lemma 1}

\begin{equation}
\sum_{r=1}^\infty f_{2r} = 1 \iff \sum_{n=0}^\infty u_{2n} = + \infty
\end{equation}

Primo passo:

\begin{equation}
u_{2n} = \sum_{k=1}^n f_{2k} u_{2(n-k)}
\end{equation}

\begin{equation}
\sum_{n=0}^\infty u_{2n} = 1 + \sum_{n=1}^\infty \sum_{k=1}^n f_{2k} u_{2(n-k)} = 1 + \sum_{k=1}^\infty f_{2k} \sum_{m=0}^\infty u_{2m}
\end{equation}

\begin{equation}
\sum_{n=0}^\infty u_{2n} = \frac{1}{1-\sum_{n=1}^\infty f_{2n}}
\end{equation}

Ovvero

\begin{equation}
\sum_{n=0}^\infty u_{2n} = + \infty \iff \sum_{k=1}^\infty f_{2k} = 1
\end{equation}

Quindi ci basta studiare la somma degli $u_{2n}$. Se $p=1/2$:

\begin{equation}
u_{2n} = {2n \choose n} \frac{1}{2^{2n}} = \frac{1+ o(1)}{\sqrt{\pi n}}
\end{equation}

Quindi la passeggiata è ricorrente. Se invece $p \neq 1/2$:

\begin{equation}
u_{2n} = {2n \choose n} p^{n} (1-p)^{n} = \frac{(4p (1-p))^n (1+o(1))}{\sqrt{\pi n}}
\end{equation}

Che converge, in quanto $4p (1-p)<1$.

La probabilità che $S_{2n} = 0$ per infiniti $n$ è 1 sse $\sum_{i=1}^\infty f_{2i} =1$

\tableofcontents

\end{document}
