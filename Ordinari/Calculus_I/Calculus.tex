\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{nicefrac}
\usepackage[margin=3.3cm]{geometry}
\usepackage{amssymb}
\usepackage{accents}
\usepackage{amsthm}
\usepackage[pdftex, pdfborderstyle={/S/U/W 0}]{hyperref}
\numberwithin{equation}{section}
\usepackage{commath}
\usepackage{graphicx}
%\usepackage[extreme]{savetrees}
\usepackage{bm}
\usepackage{indentfirst}
\usepackage{nicefrac}
\setcounter{tocdepth}{4}
\usepackage{fnpct}
\usepackage{centernot}

\usepackage{cool}
\Style{DSymb={\mathrm d},DShorten=true,IntegrateDifferentialDSymb=\mathrm{d}}

\DeclareMathOperator{\sgn}{sgn}
\usepackage{microtype}
\usepackage{cleveref}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage{mathtools}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

 
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{url}
\newcommand*{\defeq}{\stackrel{\text{def}}{=}}
\author{Jacopo Tissino}
\title{Notes on Calculus I}

\begin{document}

\maketitle

\chapter{Naïve set theory}

\section{Basic sets}

\begin{equation}
\mathbb{N} \subseteq \mathbb{Z} \subseteq \mathbb{Q} \subseteq \mathbb{R}, \qquad 0 \not \in \mathbb{N}
\end{equation}

\begin{equation}
\mathbb{R}^+ := \lbrace x \in \mathbb{R} : x>0 \rbrace
\end{equation}

\paragraph{Remarks}

\begin{itemize}
\item ``$\in$'' is for elements belonging to sets, ``$\subseteq$'' is for subsets
\item $\lbrace x \rbrace \neq x$: the first is a set with $x$ as its only element, and is called a ``singlet''
\item $\subsetneq$  means ``is a subset of, but not equal to''
\item the elements of $\mathcal{P}(A)$ are precisely all the subsets of $A$
\item $\sharp A$ is the cardinality of $A$
\item $\sharp \mathcal{P} (A) = 2^{\sharp A}$
\end{itemize}

The naïve definitions of $A \cup B$, $A \cap B$, $A \smallsetminus B$ are given.

\paragraph{Properties}

\begin{itemize}
\item $A = (A \cap B ) \cup (A \smallsetminus B)$
\item $(A \cap B) \cap (A \smallsetminus B) = \emptyset$
\item $C \cap (A \cup B) = (C \cap A) \cup (C \cap B)$
\item $C \cup (A \cap B) = (C \cup A) \cap (C \cup B)$
\end{itemize}

\paragraph{Complement}

\begin{definition}
With respect to a ``universe'' set $U$, we define the complement of $A$ as $U \smallsetminus A$, denoted $A^C$.
\end{definition}

The following hold:

\begin{itemize}
\item $(A \cup B)^C = A^C \cap B^C$
\item $(A \cap B)^C = A^C \cup B^C$
\end{itemize}

\paragraph{Cartesian product}

\begin{definition}
An \emph{ordered pair} is a set of the form $\lbrace \lbrace x \rbrace , \lbrace x, y \rbrace \rbrace$, denoted $(x, y)$ (where order matters).
\end{definition}

\begin{definition}
We define the \emph{cartesian product} $A\times B$ of two sets $A$ and $B$ as:

\begin{equation}
A\times B := \left\lbrace (a, b) : a \in A, b \in B \right\rbrace
\end{equation}
\end{definition}

\section{Propositional logic}

\paragraph{Implication}
\begin{definition}
\begin{equation}
p\implies q \iff (\neg p ) \vee q
\end{equation}
\end{definition}

\paragraph{Double implication}
\begin{definition}
\begin{equation}
(p \iff q) \iff (p \implies q \wedge q \implies p )
\end{equation}
\end{definition}

\paragraph{Quantifiers}

$P(x)$ is a \emph{predicate}. We say that $\forall x : P(x)$ if $P(x)$ is true independently of $x$, and that

\begin{equation}
\exists x : P(x) \iff \neg ( \forall x : \neg P(x) )
\end{equation}

\chapter{Number sets}

\section{The set $\mathbb{N}$}

\paragraph{The Peano axioms}

\begin{enumerate}
\item $1 \in \mathbb{N}$
\item $\forall n \in \mathbb{N}:  \exists S (n) : \mathbb{N} \rightarrow \mathbb{N}$
\item $\forall n \in \mathbb{N}: S(n) \neq 1$
\item $\forall m, n \in \mathbb{N}: m \neq n \implies S(n) \neq S(m)$ or $S(n) = S(m) \implies n = m$
\item $(A \subseteq \mathbb{N} )\wedge (1 \in A )\wedge (n  \in A \implies S(n) \in A ) \implies A = \mathbb{N}$
\end{enumerate}

Any set that verifies these axioms is isomorphic to $\mathbb{N}$. $\mathbb{R}^{+}$, for example only satisfies the first 4.

\section{Induction}

If $P(n)$ is a proposition, $P(1)$ and $P(n) \implies P(n+1)$\footnote{We introduce the notation $n+1$ to signify $S(n)$.} (the \emph{inductive hypothesis}); then $\forall n \in \mathbb{N}, P(n)$.

\begin{proof}
Define $A := \lbrace n \in \mathbb{N}: P(n) \rbrace$. By axiom 5, $A = \mathbb{N}$.
\end{proof}

If a property $a': P(k)$ holds for some $k \in \mathbb{N}$ and $b': P(n) \implies P(n+1)$, then $\forall n \geq k : P(n)$.

\paragraph{Examples}

Example: we can show by induction that

\begin{equation}
\sum_{i=1}^n = \frac{n (n+1)}{2}
\end{equation}

Example 2: we can show by induction that $P(\sharp A):\sharp \mathcal{P}(A) = 2^{\sharp A}$. 

\begin{proof}
$P(1)$ is true. 
We see that for any $A$ we can take an element such that $A = \lbrace a \rbrace \cup B$. Then for any subset $I$, either $a \in I$ or $a \not \in I$. If $a \in I$, $I = \lbrace a \rbrace \cup J$, but there are $2^n$ possible $J$s. If $a \not \in I$, we have $2^n$ $I'$s. So there are $2^{n+1}$ possible subsets.
\end{proof}

Example 3: show that $n! > 2^n$, which is true for $n>3$.

\begin{proof}
We will use the second form of the induction principle. $P(4)$ is true. If $n>4$ and $n! > 2^n$, we need to show that $(n+1) n!> 2 \cdot 2^n$. But $n+1>2$ by hypothesis, so the inequality always holds.
\end{proof}

Observation: the notation $1 + 2+ 3 + 4+ \cdots + n$ is unclear, we should use $\sum_{i=1}^n i$.

Recursive formulas: we know the first term, and an algorithm to derive any term from the one before it, such as the definition of the factorial:

\begin{equation}
\begin{cases}
0! = 1\\
(n+1)! = (n+1) n!
\end{cases}
\end{equation}

Another example is the sequence:

\begin{equation}
\begin{cases}
S_1 = 2\\
S_{n+1} = S_n + (2n+1)
\end{cases}
\end{equation}


\begin{proof}[Proof that $S_n = n^2 + 1$]
Assume that $S_n = n^2 +1$. Then $S_{n+1} = n^2 + 1 + 2n + 1 = (n+1)^2 + 1$.
\end{proof}

Formal definition of summation:

\begin{equation}
\sum_{i=0}^n a_i =a_0 + a_1 + a_2 + a_3 + \cdots + a_n
\end{equation}

by recursion: for an increment in $n$, we just add the $n+1$-th term. So it comes down to the formal definition of induction.

Example: show by induction that

\begin{equation}
\forall a \in \mathbb{N} \vee a=0 \quad (a\neq 1): \quad \sum_{k=0}^n a^k = \frac{1-a^{n+1}}{1-a}
\end{equation}

See the property for $n=0$. Suppose that the property holds for $n$, show it for $n+1$:

\begin{equation}
\sum_{i=0}^{n+1} a_k = \sum_{k=0}^n a^k + a^{n+1} = \frac{1-a^{n+1}}{1-a} + a^{n+1} = \frac{1-a^{n+2}}{1-a}
\end{equation}

To do: given two real numbers, $\forall n \in \mathbb{N}$, show that

\begin{equation}
(a+b)^n = \sum_{k=0}^n {n\choose k} a^k b^{n-k}
\end{equation}

\section{Groups}

We have a set $A$ with an operation $*$: $a, b \in A \rightarrow a*b \in A$. Es: $A$ strings, $*$ concatenation. $(A, *)$ is a group if the following are satisfied:

\begin{enumerate}
\item Associativity: $\forall a, b, c \in A: \quad a* (b*c) = (a*b)*c$
\item Identity: $\exists e \in A: \forall a \in A: \quad e*a = a*e = a$
\item Inverse: $\forall a \in A: \exists a^{-1} \in A: \quad a* a^{-1} = a^{-1} * a = e$
\end{enumerate}

$(A, *)$ is also a commutative group if $\forall a, b \in A: \quad a*b=b*a$

Examples: $(\mathbb{N}, +)$ is not a group: there is no identity, but even if we add 0 there is no inverse. $(\mathbb{Z}, +)$ is a commutative group. $(\mathbb{R}, \times)$ is not a group because 0 has no inverse. $(\mathbb{R}_0, \times)$ is hower a group, as is $(\mathbb{R}_0, +)$. $(\mathbb{Z}_0, \times)$ is not a group because there is no inverse: $(\mathbb{Q}_0, \times)$ is a commutative group.

So we introduce $\mathbb{Q}$:

\begin{equation}
\mathbb{Q}:= \left\lbrace \frac{a}{b}, a \in \mathbb{Z}, b\in \mathbb{N}\right\rbrace  / \sim
\end{equation}

but $ad \sim bc$ and $\mathbb{Q}$ is isomorphic to $\mathbb{Z}$

\begin{definition}
Order relation:

\begin{equation}
\frac a b \leq \frac cd \iff ad \leq bc 
\end{equation}
\end{definition}

\begin{definition}
Sum and product, subtraction and division are analogous:

\begin{equation}
\frac ab + \frac cd = \frac{ad+bc}{bd}
\end{equation}
\begin{equation}
\frac ab \times \frac cd = \frac{ac}{bd}
\end{equation}
\end{definition}

$(\mathbb{Q}, +, \times)$ is then a field:

\begin{enumerate}
\item $(\mathbb{Q}, +)$ is a commutative group;
\item $(\mathbb{Q}_0, \times )$ is a commutative group
\item $p (q+r) = pq + pr$
\end{enumerate}

\paragraph{Roots}

The square root of a number $a\geq 0$ is a $b \geq 0$ such that $b^2 = a$.

Show that in $\mathbb{Q}$ there is no $\sqrt{2}$:

\begin{proof}
By contradiction:\footnote{In the form: to show that $p \implies q$, we show that $\neg q \implies \neg p$, since
\begin{equation}
(p\implies q) \iff (\neg q \implies \neg p )
\end{equation}} if there were $a \in \mathbb{Z}$ and $b \in \mathbb{N}$ such that

\begin{equation}
\left( a\over b \right) ^2 = 2
\end{equation}

Suppose that $a, b$ have $\gcd(a, b) = 1$. Then $a^2 = 2 b^2$. So $a$ is even, and $a=2k$.

Then $4k^2 = 2b^2 \implies b=2n$: so $\gcd(a, b) \neq 1$
\end{proof}

With the same reasoning we can show that numbers such that $\sqrt{3}$ and $\sqrt[3]{2}$ are irrational.

\section{The set $\mathbb{R}$}

The set is given.
$\mathbb{R}$ is a completely ordered field:

\begin{enumerate}
\item $(\mathbb{R}, +)$ is a commutative group
\item $(\mathbb{R}_0, \times)$ is a commutative group
\item $a (b+c) = ab+ac$
\end{enumerate}

There also exists a relation called $\leq$, such that $\forall a, b, c \in \mathbb{R}$:

\begin{enumerate}
\item $a\leq a$
\item $a \leq b \wedge b \leq a \implies a = b$
\item $a \leq b \wedge b \leq c \implies a \leq c$
\item $a \leq b \vee b \leq a$ (\emph{completely} ordered)
\item $a \leq b \implies a+c \leq b+c$
\item $a \geq 0 \wedge b \geq 0 \implies ab \geq 0$ (of course, $a \geq 0$ means that $0 \leq a$) 
\end{enumerate}

$(\mathbb{Q}, +, \times) $ is also a completely ordered field?

Take the set of all the real numbers whose squares are greater or equal to 2: it has a minimum.

In $\mathbb{Q}$, it has no minimum.

Other statements: show that $a \leq 0 \wedge b \geq 0 \implies ab \leq 0$

\begin{proof}
Is $a \geq 0 \wedge -b \geq 0$? We first need to show that $a \geq 0 \iff -a \leq 0$: it suffices to add $-a$ to both sides. We also need to show that $a (-b) = -ab$: by an inverse application of the distributive property.
\end{proof}

\paragraph{Useful inequalities}

$\forall x \in \mathbb{R}: x^2 \geq 0$. Also, $\forall a, b \in \mathbb{R}: ab \geq (a^2 + b^2)/2$ (one of the inequalities between the means. From this, we can also show that between the rectangles of perimeter $p$, the square is the one with the largest area.

TO DO: show this for parallelograms and trapezes.

\paragraph{Integer part of a number} Given an $x \in \mathbb{R}$, we define its integer part $\lfloor x \rfloor = n \in \mathbb{Z}$ as the largest integer such that $n\leq x$.\footnote{This is also the case for negative numbers: so the integer part of a negative real number may have greater absolute value than the number itself.}

The fractionary part $\lbrace x \rbrace$ is defined as

\begin{equation}
\lbrace x \rbrace = x - \lfloor x \rfloor
\end{equation}

It is clear that $x-1 < \lfloor x \rfloor \leq x$ and that $0 \leq \lbrace x \rbrace  < 1$, and that $\lfloor x \rfloor =x \iff x \in \mathbb{Z}$

\section{Set notation}

The notation $[a; b]$ means $\left\lbrace x \in \mathbb{R}: a \leq x \leq b\right\rbrace$, and $(a; b) = ]a;b[$ means $\left\lbrace x \in \mathbb{R}: a < x < b\right\rbrace$. These are \emph{closed} and \emph{open} sets. We can combine the two types of brackets as we wish.

In the notation $(a; + \infty )$, the symbol $\infty$ is not a number.

\begin{definition}
We define the maximum of a set $E\subseteq \mathbb{R}$, denoted $\max E$ (and analogously $\min E$), as a number $M \in \mathbb{R}$ with the following properties:
\begin{enumerate}
\item $\forall x \in E: M \geq a$ ($M$ is an upper bound of $E$)
\item $M \in E$
\end{enumerate}
\end{definition}

A set is limited from above if it has an upper bound, and from below if it has a lower bound.
Open sets can be limited, but they do not have maximums and minimums: we can show this by taking the average between the first real number outside of the set and a number we suppose to be this maximum, getting to a contradiction.

\begin{definition}
We define the \emph{least upper bound} of a set $E$ as the minimum of the set of the upper bounds, and analogously for lower bounds. We can do this $\forall E \subseteq \mathbb{R}: E \neq \emptyset$, and we denote them as $\inf E$ and $\sup E$.
\end{definition}

If $E$ does not have an upper limit, we write $\sup E = + \infty$, but this is just notation. The same goes for $\inf E = -\infty$. It is also common to write $\sup \emptyset = - \infty$ and $\inf \emptyset = + \infty$, but defining them this way makes the fact $\inf E \leq \sup E$ not true.

$E$ has a maximum iff $\sup E \in E$. If $E \neq \emptyset \neq F$ and $E \subseteq F$, then $\sup E \leq \sup F$ and $\inf F \leq \inf E$.

\begin{theorem}[Archimedes' axiom]
Given $a, b \in \mathbb{R}$, where $a>0$ and $b>0$, $\exists n\in\mathbb{N}: na>b$.
\end{theorem}

\begin{proof}
We choose $n = \lfloor b/a \rfloor +1$.
\end{proof}

\paragraph{Axiom of continuity or completeness} Given $E \subseteq \mathbb{R}$, $E\neq\emptyset$, with at least an upper bound, there exists $\sup E \in \mathbb{R}$. The inverse is easily proven from this.

$\mathbb{R}$ (and sets which can be bijectively mapped to it, via a map that preserves addition and multiplication) is the only totally ordered set which verifies the axiom of continuity.

\begin{theorem}
$\sup E = M \iff \forall x \in M: x \leq M$ and $\forall \epsilon > 0: \exists z \in E : z>M-\epsilon$.
\end{theorem}

\begin{proof}
We will prove the leftward implication by contradiction. Suppose there exists an $M'<M$. Then $\forall \epsilon \in E: z \leq M'$. But define $\epsilon := (M-M')/2$:then ???
*Prove the rightward implication*
\end{proof}

\paragraph{Halved intervals}

\begin{theorem}
Take $a_k, b_k \in \mathbb{R}: \forall k \in \mathbb{N}: a_k < b_k$ and $\forall k \in \mathbb{N}: [a_{k+1}; b_{k+1}]$ is one of the halves of $[a_k; b_k]$:

\begin{equation}
\forall k: [a_{k+1}, b_{k+1}] = \left[a_k, \frac{a_k + b_k}{2}\right] \vee \left[\frac{a_k + b_k}{2}, b_k\right]
\end{equation}

Then $\exists ! \lambda \in \mathbb{R}: \forall k \in \mathbb{N}: \lambda \in [a_k; b_k]$. We can write this as

\begin{equation}
\bigcap_{k=1}^{+\infty} [a_k; b_k] = \lbrace \lambda \rbrace
\end{equation}

$\lambda$ is clearly the $\sup \lbrace a_k: k \in \mathbb{N}\rbrace = \inf \lbrace b_k: k \in \mathbb{N}\rbrace$.
\end{theorem}

\begin{proof}
First, we will show that $\forall k, j \in \mathbb{N}: a_k < b_k$.

\begin{itemize}
\item $k\geq j$: $a_k < b_k \leq b_j$;
\item $k< j$: $a_k \leq a_j < b_j$.
\end{itemize}

so, $\forall k \in \mathbb{N}$, $a_k$ is a lower bound for $\lbrace b_j: j \in \mathbb{N}\rbrace$: $\forall k: a_k \leq \inf \lbrace b_j\rbrace$. So, $\inf \lbrace b_j \rbrace \leq \sup \lbrace a_k \rbrace $ (these must exist since the sets are bounded).

We can see this as:

\begin{equation}
\forall n \in \mathbb{N}: 0 \leq \inf \lbrace b_j \rbrace - \sup \lbrace a_k \rbrace \leq b_n - a_n = \frac{b_1- a_1}{2^{n-1}}
\end{equation}

It is clear that if $x \geq 0$ and $\forall \varepsilon > 0: x \leq \varepsilon$, then $x=0$.

Also, $\forall \varepsilon > 0: \exists n \in \mathbb{N}: n\varepsilon > b_1 - a_1$ by Archimedes' property. But $\forall n \in \mathbb{N}: n \leq 2^{n-1}$. So

\begin{equation}
\forall \varepsilon > 0: \exists n \in \mathbb{N} : 0 \leq \inf \lbrace b_j \rbrace - \sup \lbrace a_k \rbrace \leq b_n - a_n = \frac{b_1- a_1}{2^{n-1}} < \varepsilon
\end{equation}

which implies $ \inf \lbrace b_j \rbrace = \sup \lbrace a_k \rbrace := \lambda \in \mathbb{R}$.
\end{proof}

This doesn't just work for halved intervals: any set of intervals for which $[a_{k+1}, b_{k+1}]\leq [a_k, b_k]$ and $\lim_{k \rightarrow +\infty} b_k - a_k =0$:

\begin{proof}
We need to show the two inclusions in 

\begin{equation}
\cap_{k=1}^{+\infty} [a_k, b_k] = \lambda
\end{equation}

$\lambda = \sup \lbrace a_k \rbrace = \inf \lbrace b_j \rbrace$, so $\forall k: \lambda \in [a_k, b_k]$.

We need to show that if $x \in \cap_{k=1}^{+\infty} [a_k, b_k]$, then $x = \lambda$. 

If $\forall k: a_k \leq x \leq b_k$, then $x$ is an upper bound of $\lbrace a_k \rbrace$ ($x \geq \sup \lbrace a_k \rbrace$) and a lower bound of $\lbrace b_k \rbrace$ ($x \leq \inf \lbrace b_k \rbrace$). So, $x = \lambda$.
\end{proof}

\chapter{Topology}

We will focus on the topology of $\mathbb{R}$, sometimes generalizing to $\mathbb{R}^n$.

A \emph{metric space} is couple $(X, \text{d})$, where $\text{d}: X\times X \rightarrow \mathbb{R}$ is a \emph{distance} function, satisfying $\forall x, y, z \in X$:

\begin{enumerate}
\item $\text{d}(x, y) \geq 0$; $\text{d} (x, y) = 0 \iff x=y$;\label{positivity-distance}
\item $\text{d}(x, y) = \text{d}  (y, x)$;\label{symmetry-distance}
\item $\text{d}(x, y) \leq \text{d}(x, z) + \text{d}(y, z)$ (the triangular inequality).\label{triangular-distance}
\end{enumerate}

On $\mathbb{R}$, the distance function is usually $\text{d}(x, y) = \abs{x-y}$.\footnote{This is not our only option: something like $\text{d}(x, y) = \sqrt{\abs{x-y}}$ would work as well.}

This extends to $\mathbb{R}^n$:

\begin{equation}
\text{d}(x, y) = \sqrt{\sum_{i=0}^n (x_i - y_i)^2}
\end{equation}

This clearly satisfies conditions \ref{positivity-distance} and \ref{symmetry-distance}, but we have to prove condition \ref{triangular-distance}:

\begin{proof}
This follows from the subadditivity of the norm of vectors: $\mathbb{R}^n$ is a vector space, and we can interpret $\text{d}(x, y)$ as $\norm{\mathbf{x}-\mathbf{y}}$, so in the equation $\norm{\mathbf{x}+\mathbf{y}} \leq \norm{\mathbf{x}} + \norm{\mathbf{y}}$ we substitute $\mathbf{x}= u-z$ and $\mathbf{y}= z-v$.
\end{proof}

\section{Balls and openness}

Given the metric space $(X, d)$, with $x_0 \in X$ and $r>0, r\in \mathbb{R}$, we denote as $B(x_0, r)$ (or sometimes $B_r (x_0))$ the ``ball'':

\begin{equation}
B(x_0, r) = \lbrace x \in X: \text{d}(x, x_0) < r \rbrace
\end{equation}

For example, in $\mathbb{R}$ this looks like $(x_0 -r, x_0 + r)$.

\begin{definition}
Given the metric space $(X, d)$, and $E \subseteq X$, $x \in X$, we say that $x$ is internal to $E$ if $\exists r \in \mathbb{R}, r>0: B(x, r) \subseteq E$ (E intorno di X).
\end{definition}

\begin{definition}
Given the metric space $(X, d)$, and $E \subseteq X$, $x \in X$, we say that $x$ is external to $E$ if $\exists r\in \mathbb{R}, r>0: B(x, r) \cap E =\emptyset$. $x$ is thus internal to the complement of $E$.
\end{definition}

\begin{definition}
$x$ is a frontier (or boundary) point if it is neither internal nor external.
\end{definition}

We denote the set of internal points of $E$ as $\overset{\circ}{E}$ or $\text{int} E \subseteq E$, the boundary as $\partial E$, and the external points as $E^e$.

For example, in $\mathbb{R}^n$, if $E= B(x_0, r)$,  $\norm{x-x_0} < r \iff x \in \overset{\circ}{E}$ because of the triangular inequality: $B(x, (r- \norm{x-x_0})) \subseteq B(x_0, r)$. We can see that for any $y$ $\text{d}(y, x_0) \leq \text{d}(y, x) + \text{d} (x_0, x)$.

Also, if $\norm{x-x_0} > r$, $x \in E^e$, since we can construct $B(x, \norm{x-x_0} - r) \in E^C$.

If $\norm{x-x_0} = r$, $x \in \partial E$ since we can construct $B(x, p)$ for some $p>0$, and supposing  WLOG that $p<r$ we can show that:

\begin{align}
B(x, p) \diagdown E \neq \emptyset &\Leftarrow ( x \in E^C \implies \forall t>0 x \in B(x, t))\\
B(x, p) \cap E \neq \emptyset &
\end{align}

We can prove the last statement by defining

\begin{equation}
y:= x + \frac p2 \left( \frac{x-x_0}{r} \right)
\end{equation}

and showing that $\text{d}(y, x_0)<r$. 

It is easily proven that $\partial \mathbb{Q} = \mathbb{R}$, and that $\partial E = \partial(E^C)$.

\subsubsection{Open sets}

\begin{theorem}
$E\subseteq X$ is open, that is, $\overset{\circ}{E} =E$, iff $E \cap \partial E = \emptyset$.
\end{theorem}

This clearly implies that $\forall E \subseteq X : \overset{\circ}{E}$ is open. $E^e$ is also open. We conventionally say that $\emptyset$ is open.

\begin{proof}
Rightward: if $x \in E$, and $E$ is open, then every point is internal, so it is not a frontier point.

Leftward: if $x \in E$, $x \notin \partial E$, and it is not external, so $x \in \overset{\circ}{E}$.
\end{proof}

\begin{theorem}
A union (finite or infinite) of open sets is open.
\end{theorem}

\begin{proof}
If $x \in \cup E_i$, $\exists k: x \in E_k$, so $\exists r>0: B(x, r) \subseteq E_k \subseteq \cup E_i$.
\end{proof}

\begin{theorem}
If $A$ and $B$ are open, $A \cap B$ is open.
\end{theorem}

\begin{proof}
Take $x \in A \cap B$. Then, $\exists r_1, r_2 > 0: B(x, r_1) \subseteq A$ and $B(x, r_2) \subseteq B$. If we take $r := \min\lbrace r_1, r_2\rbrace$ we have $B(x, r) \subseteq A \cap B$.
\end{proof}

By induction we can see that, if $\forall i: A_i$ is open, then $\cap_{i=0}^\infty A_i$ is open. This, however, does not generalize to infinite intersections.

\subsubsection{Closed sets}

In a metric space $X$, $D\subseteq X$ is closed if $D^C$ is open. Intervals like $[a, b] \subseteq \mathbb{R}$ are closed. $\lbrace a \rbrace \subseteq \mathbb{R}$ is also closed.

\begin{theorem}
$D$ is closed iff $\partial D \subseteq D$, that is, $D = \overset{\circ}{D} \cup \partial D$.

$D$ is closed iff $D^C \cap \partial (D^C) = \emptyset$, that is, $\partial D \subseteq (D^C)^C = D$.
\end{theorem}

\begin{theorem}
A finite union of closed sets is closed.
\end{theorem}

\begin{proof}
\begin{equation}
\left( 
\bigcup_{i=0}^n D_i
\right)^C
=\bigcap_{i=0}^n
\left(
D_i
\right)^C
\end{equation}
\end{proof}

\begin{theorem}
A (finite or infinite) intersection of closed sets is closed.
\end{theorem}

\begin{proof}
\begin{equation}
\left( 
\bigcap_{i=0}^n D_i
\right)^C
=\bigcup_{i=0}^n
\left(
D_i
\right)^C
\end{equation}
\end{proof}

\paragraph{Closure}

\begin{definition}
The \emph{closure} of a set $E$, denoted $\bar{E}$, is $\bar{E}:= \overset{\circ}{E} + \partial E$.
\end{definition}

$E$ is closed iff $\bar{E} = E$. $\bar{E}$ is always closed since $(\bar{E})^C$ is open. $\overset{\circ}{E} \subseteq E \subseteq \bar{E}$.

\begin{theorem}
$\bar{E}$ is the smallest closed set containing $E$: if $D$ is closed and $E \subseteq D$, then $\bar{E}\subseteq D$.
\end{theorem}

\begin{proof}
$D^e \subseteq E^e = \bar{E}^e$. If we take an $x \in \bar{E}$, $x$ cannot belong to $\bar{E}^e$. This means it also does not belong to $D^e$, so $x \in \overset{\circ}{D} \vee x \in \partial D \implies x \in D$.
\end{proof}

\section{Limit points}

\begin{definition}
Take the set $E \subseteq \mathbb{R}^n$: $x_0 \in \mathbb{R}^n$ is a limit point for $E$ if

\begin{equation}
\forall r>0: \exists x \in E, x\neq x_0 : x \in B(x_0, r)
\end{equation}

Equivalently, $B(x_0, r)$ contains infinite points of $E$.

The set of the limit points of $E$ is denoted $\mathcal{D}E$: it is called ``derived set''.
\end{definition}

If $x \in E^e$, then $x \notin \mathcal{D}E$; also if $x \in \overset{\circ}{E}$ then $x \in \mathcal{D}E$. This holds in $\mathbb{R}^n$, but it might not in pathological metric spaces.

So we have $\overset{\circ}{E} \subseteq \mathcal{D}E \subseteq \bar{E}$.

Some examples: $\mathcal{D}\mathbb{Z} = \emptyset$, $\mathcal{D}(a, b) = [a, b]$.

\begin{theorem}
$D$ is closed iff it contains all of its limit points.
\end{theorem} 

\begin{proof}
Rightward implication: $\mathcal{D} D \subseteq \bar{D} = D$.

Leftward implication: by contradiction. Suppose that $\partial D \nsubseteq D$. Then $\exists x \in \partial D \smallsetminus D$, so $\forall r>0: \exists y \in B(x, r) \cap D$. But $y \in D$, and $x \notin D$, so $y\neq x$: $x$ is a limit point, which implies $x \in D$.
\end{proof}


\begin{theorem}
Given $a, b \in \mathbb{R}$, $\exists r \in \mathbb{Q}: a<r<b$. ($\mathbb{Q}$ is dense in $\mathbb{R})$.
\end{theorem}

\begin{proof}
By Archimedes' property, the multiples of $k^{-1}$ ($k \in \mathbb{N}$) will always exceed $a$. We can choose a $k$ such that $k(b-a)>1$. Then, 

\begin{align}
ka &< \floor{ka} +1 \leq ka+1 < kb\\
a &< \frac{\floor{ka} +1}{k} < b
\end{align}
\end{proof}

So, $\bar{\mathbb{Q}} = \mathcal{D}\mathbb{Q} =\mathbb{R}$. We can also easily prove that $\mathcal{D}(\mathbb{R}\smallsetminus \mathbb{Q}) = \mathbb{R}$, and $\overset{\circ}{\mathbb{Q}} = \emptyset$.

If $E\subseteq \mathbb{R}$ is finite, $\mathcal{D}E = \emptyset$.

\begin{theorem}
If $E\subseteq \mathbb{R}$ is limited and infinite, then $\mathcal{D}E \neq \emptyset$.
\end{theorem}

\begin{proof}
We can split $E$ in two parts, taking the average of $\sup E$ and $\inf E$. Then, in one of the sets into which we split $E$ there must still be infinitely many points. We can apply the same splitting process to it, and so on: by the Halved Intervals theorem in the end the intersection of the sets we selected on each iteration will contain just one element $\lambda \in E$, and by construction $
\lambda \in \mathcal{D}E$.
\end{proof}

This also holds in $\mathbb{R}^n$.

\chapter{Functions}

\section{Basics}
Given two nonempty sets $A$ and $B$, a function $f: A \rightarrow B$ is a subset of $A \times B$ such that each elements of $A$ appears in exactly one of the ordered pairs $(a, b): a \in A, b \in B$.

$A$ is called \emph{domain}, $B$ is called \emph{range}. The \emph{image} of a set $X \subseteq A$ is $f(X) = \lbrace y \in B: \exists x \in X: f(x) = y\rbrace$. A function is \emph{surjective} if $f(A) = B$. Similarly, the \emph{preimage} of a set $Y \subseteq B$ is $f^{-1}(Y) = \lbrace x \in A: \exists y \in Y: f(x) = y\rbrace$.

\paragraph{Composition}

Given $f: A \rightarrow B$ and $g: B \rightarrow C$, $\exists h:= g \circ f: A\rightarrow C$ such that $g\circ f)(x) = g(f(x))$.

For convenience, given an expression in the variable $x$, we automatically assume it represents a function $f:A\rightarrow\mathbb{R}$, which associates every $x$ with the expression evaluated at that point. $A$ is the largest subset of $\mathbb{R}$ for which the function is defined.

\paragraph{Injectivity}

$f:A\rightarrow B$ is injective if $\forall x_1, x_2 \in A: x_1 \neq x_2 \implies f(x_1) \neq f(x_2)$.

Given an injective function, we can define an inverse: $f^{-1}: f(A) \rightarrow A$, where $f^{-1}(y) = x \in A: f(x) =y$.

$\forall x \in A: f^{-1} \circ f (x) = x$ and $\forall y \in f(A): f\circ f^{-1}(y) = y$.

An inverse function is always bijective.

\begin{definition}
Given the subset $A \subseteq \mathbb{R}$, $f:A \rightarrow \mathbb{R}$ is said to be increasing if $\forall x_1, x_2 \in A: x_2 >x_1 \implies f(x_2) \geq f(x_1)$, decreasing if $f(x_2) \leq f(x_1)$. It is \emph{strictly} increasing or decreasing if the inequalities are strict.
\end{definition}

\begin{definition}
$f$ is even if $f(-x) = f(x)$, and odd if $f(-x) = -f(x)$.
\end{definition}

\section{Basic functions}

\paragraph{Powers}

$f(x) = x^\alpha $ is easily defined $\forall x \in \mathbb{R}$ if $\alpha \in \mathbb{Q}$ and its denominator is odd, and only for positive numbers if is even.

In general, though, if $\alpha \notin \mathbb{Q}$ and $\alpha > 0$:

\begin{equation}
x^\alpha=\begin{cases}
\sup \left\lbrace x^p: p \in \mathbb{Q}, p < \alpha \right\rbrace \qquad x\geq 1  \\
\inf \left\lbrace x^p: p \in \mathbb{Q}, p < \alpha \right\rbrace \qquad 0\leq x<1 
\end{cases}
\end{equation}

If $\alpha<0$, $x^\alpha := (x^{-\alpha})^{-1}$.

\paragraph{Trig functions}

As usual.

\paragraph{Logs}

\begin{definition}
Given $a>0$, $a\neq 1$, $x>0$, we define: $\log_a x = p \iff a^p = x$.
\end{definition}

Some properties are:
$\log_{a^{-1}} x = -\log_a x$, $\log_b x = \log_b a \cdot \log_a x$. 

\paragraph{Misc}

$\sgn x$ is defined as usual, and $\sgn 0 = 0$.

\begin{definition}
Given a function $f: A \rightarrow B$, and $D \subset A$, we can restrict $f$ to $D$: the function $f_{|D}: D\rightarrow B$ is defined by $\forall x \in D: f_{|D} (x) = f(x)$.
\end{definition}

\paragraph{Inverses}

Since $\sin$, $\cos$ and $\tan$ are not injective, to invert them we have to restrict their domain: $\arcsin$ is the inverse of $\sin_{|[-\pi/2, \pi/2]} x$, $\arccos x$ is the inverse of $\cos_{|[0, \pi]} x$
 and $\arctan$ is the inverse of $\tan_{|]\-\pi/2, \pi/2[} x$.
 
\section{Some other properties}

\begin{definition}
A function $f: A \rightarrow \mathbb{R}$ is bounded by above if $\exists M \in \mathbb{R}: \forall x \in A: f(x) \leq M$; that is, $\sup \lbrace f(A)\rbrace \in \mathbb{R}$.
The definition is analogous for functions that have a lower bound.

A function is bounded if it has a lower and upper bound; that is, $\abs{f(x)}$ has an upper bound.
\end{definition}

\begin{definition}
The upper bound of $f$ in $A$ is the $\sup \lbrace f(A) \rbrace$, it is often denoted $\sup_A f$ or $\sup_{x \in A} f$.
\end{definition}

\begin{definition}
$x_0 \in A$ is a maximum for $f$ in $A$ if $\forall x \in A: f(x) \leq f(x_0)$. It is often denoted $\max_A f$ or $\max_{x\in A} f$.
\end{definition}

The following hold:

\begin{align}
\forall x \in A: f(x)\leq &\sup_A f \\
\forall \varepsilon > 0: \exists z \in A : f(z) > &\sup_A f - \varepsilon
\end{align}

\chapter{Limits}

\section{Definitions}

\begin{definition}
Given $D\subseteq \mathbb{R}$, $f: D \rightarrow \mathbb{R}$, and a limit point $x_0 \in D$, we say that $\lim_{x\rightarrow x_0} f(x) = L$ iff

\begin{equation}
\forall \varepsilon > 0: \exists \delta > 0 : f(     D \cap B (x_0, \delta)\smallsetminus \lbrace x_0 \rbrace ) \subseteq B(L, \varepsilon)
\end{equation}
\end{definition}

Since $x_0$ is a limit point, $\forall \delta >0: ]x_0 - \delta, x_0 +\delta[ \smallsetminus \lbrace x_0 \rbrace \neq \emptyset$. The value of $f(x_0)$ is irrelevant. The value of $\delta$ we choose depends both on $\varepsilon$ and $x_0$; if it works for $\varepsilon_1$ it must also $\forall \varepsilon > \varepsilon_1$.

\section{Properties}

\begin{theorem}
Given $D\subseteq \mathbb{R}$, $f, g: D \rightarrow \mathbb{R}$, and a limit point $x_0 \in D$. If

\begin{equation}
\lim_{x \rightarrow x_0} f(x) = L \in \mathbb{R} \wedge \lim_{x \rightarrow x_0} g(x) = M \in \mathbb{R}
\end{equation}

then

\begin{align}
\lim_{x \rightarrow x_0} f(x) + g(x) &= L + M \\
\lim_{x \rightarrow x_0} f(x) g(x) &= LM \\
\lim_{x \rightarrow x_0} \frac{f(x)}{g(x)} &= \frac{L}{M} \quad \text{as long as } M \neq 0
\end{align}
\end{theorem}

\begin{proof}[Additivity]
\begin{align}
\forall \varepsilon > 0 : \exists \delta_1 > 0: &\forall x \in D : 0 < \abs{x-x_0} <\delta_1 \abs{f(x) - L} < \varepsilon  \\
\forall \varepsilon > 0 : \exists \delta_2 > 0: &\forall x \in D : 0 < \abs{x-x_0} <\delta_2 \abs{g(x) - M} < \varepsilon  
\end{align}

We can take $\delta := \min \lbrace \delta_1, \delta_2 \rbrace$. Then

\begin{align}
&\forall \eta = 2\varepsilon > 0 : \exists \delta > 0: \forall x \in D : \nonumber \\
&0 < \abs{x-x_0} <\delta \abs{f(x) + g(x) - (L+M)} \leq \abs{f(x) -L} + \abs{g(x) - M} < \eta 
\end{align}
\end{proof}

\begin{proof}[Multiplicativity]
We will use $f$ and $g$ as shorthand for $f(x)$ and $g(x)$. Then, setting the same $\delta$ as before, we have that $\forall x \in D: 0 < \abs{x - x_0} < \delta$:

\begin{align}
&\abs{fg-LM} \leq \abs{fg-Lg} + \abs{Lg - LM}  \\
&= \abs{g}\abs{f-L} + \abs{L} \abs{g-M}     < \left( \abs{g} + \abs{L}\right) \varepsilon\\
&< \left( 1 + \abs{M} + \abs{L}\right) \varepsilon
\end{align}

The last step is justified since, if $\varepsilon < 1$, $g \in [M-1, M+1]$.
\end{proof}

\begin{proof}[Divisibility]
We can say that $\forall \varepsilon > 0 $ there  $\exists \delta > 0$ such that:

\begin{align}
\abs{\frac{f}{g}- \frac{L}{M}}
&\leq\frac{\abs{M} \abs{f-L} + \abs{L} \abs{g-M}}{\abs{g} \abs{M}}\\
&< 2 \left( \frac{\abs{M} + \abs{L}}{M^2} \right) \varepsilon
\end{align}
\end{proof}

\begin{theorem}
If the limit exists, it is unique.
\end{theorem}

\begin{proof}
By contradiction: suppose both $L$ and $M$ were limits. Then by linearity

\begin{equation}
L-M = \lim_{x \rightarrow x_0} f(x) - f(x) = \lim_{x \rightarrow x_0} 0 = 0
\end{equation}
\end{proof}

\paragraph{Change of variable}

\begin{theorem}
If $\lim_{x \rightarrow x_0} f(x) = L $ and $\lim_{y \rightarrow L} g(y) = M$, and $g$ is continuous in $L$, then

\begin{equation}
\lim_{x \rightarrow x_0} g(f(x)) = M
\end{equation}
\end{theorem}
 
\paragraph{Squeeze theorem}

Given $D \subseteq \mathbb{R}$, a limit point $x_0 \in D$, and $f, g, h: D \rightarrow \mathbb{R}$ such that $\forall x \in D: f \leq g \leq h$:

\begin{equation}
\lim_{x\rightarrow x_0} f(x) = \lim_{x \rightarrow x_0} h(x) = L \implies \lim_{x \rightarrow x_0} g(x) = L
\end{equation}
 
\tableofcontents

\end{document}
